# Experiments

This folder is intended for the storing of all the outputs of the active machine learning worflow as described in the main [paper](https://doi.org/10.26434/chemrxiv-2024-frnj3).

## General folder organization:

    1.experimentID/
    ├── cycles/
    │   ├── cycle_0/
    │   │   ├── experimentID_cycle0_ouput_points.csv
    │   │   ├── experimentID_cycle0_ouput_points.ndx
    │   │   ├── experimentID_cycle0_ouput_points_pdf.npy
    │   │   ├── experimentID_cycle0_ouput_barcodes.csv 
    │   │   ├── experimentID_cycle0_ouput_algorithm.pkl 
    │   │   ├── experimentID_cycle0_validated_points.csv
    │   │   └── experimentID_cycle0_config_file.json
    │   ├── cycle_1/
    │   │   ├── experimentID_cycle1_ouput_points.csv
    │   │   ├── experimentID_cycle1_ouput_points.ndx
    │   │   ├── ...
    │   │   └── ...
    │   └── cycle_N/
    │
    ├── dataset/
    │   ├── DesignSpace_experimentID.csv
    │   └── DesignSpace_config.json
    │    
    └── figures/

    ground_truth/

    ManualLab_experiments/

    overfitting_tests/

    RoboLabSynt_2D_A/

    master_file/
    ├── master_file_version_0.csv
    ├── master_file_version_1.csv
    └── master_file_version_N.csv

## Files & outputs

Each `experimentID/` folder contains the data that was used from or generated by the active machine learning routine:
-   `cycle_n/`, contains the outputs for each completed cycles, most importantly the screened/validated points and the phase diagram prediction.
-   `dataset/`, contains the selected design space for the current experiment. Here at every cycle the validated points will be appended to create a screened dataframe of points.

Other folders serves different purposes:
-   `master_file/`, contains a backupd of the points screened for all the experiments, for all the cycles, with a unique identifier (only for traking purposes).
-   `ground_truth/`, contains the ground truths dataframes collected from the different experiments.
-   `ManualLab_experiments/`, contains some comparison of our AL method with non-ML strategies.
-   `overfitting_tests/`, contains overfitting tests run on the current setup.
-   `particle_features_data/`, contains the particles feature data extracted from the microscope.
-   `RoboLabSynt_2D_A`, contains a complete in-silico test using a _dummy_ phase diagram that contains multiple separate pahses.


## Setting up experiments

The setup for an experiment requires a few steps:

### 1. Update of the `format.py`

The `repo/robotexperiments/format.py` file contains core information about the location of the folder regarding experiments, the master-file, and other essential global variables to run the experiments.\
_Disclaimer_: _this was mainly necessaty due to out local setup for running the experiments!_

### 2. Design the search-space dataframe

To create the dataframe containing the pool of points to be screened by the algorithm we can run the script from the `repo/script/experiments/` folder:
```bash
python repo/script/experiments/experiment_init.py -phasevar phasevar_config.json
```
The script needs an input file containing instructions on the ranges of the experimental values of the variables to screen during the experiments.
The following is an example of input config file:

```json
{
    "Experiment_ID" : "ExpID_XXX",
    "phase_diagram_variables" : {
        "X" : {"start":0.1, "end":8.0, "ev":0.1},
        "Y" : {"start":0.1, "end":8.0, "ev":0.1},
        "Z" : {"start":100, "end":2000, "ev":100},
        "Phase" : -1
    }
}
```
The file is also available in the folder, `phasevar_config_example.json`.  

Running
```bash
python repo/script/experiments/experiment_init.py -h
```
gives access to the complete list of functionalities.

### 3. Running the cycles

To run the experiments the [ActiveLearningCLassiFier](https://github.com/AGardinon/ActiveLearningCLassiFier) package is required (_included in the `environment.yml`_).
The package allows to apply the point selection and classification strategies to an input dataset at each cycle.

The general cycle is evaluated by running the `active_learning_cycle.py` from the `repo/script/cycle/` folder:
```bash
python repo/script_cycles/active_learning_cycle.py
```
The script input dictionary needs to be adjusted depending on the needs and it contains all the information about the experiment cycle.
The input variables are defined inside the script (for the individual evaluation) but it can be leverage for automatic experiments.\
_Disclaimer_: _the current set up was mainly created due to out local setup for running the experiments!_

```python
# --- Variables

experimentID = 'robot001'
cycle_number_tmp = 1
new_points_batch_tmp = 18

classifier_dict_tmp = {
    'kernel': ['*', {'type': 'C', 'constant_value': 1.0}, {'type': 'RBF', 'length_scale': 1.0}],
    'n_restarts_optimizer': 5,
    'max_iter_predict': 150,
    'n_jobs': 3
}

acquisition_mode_tmp = 'exploration'

experiment_cycle_dict_tmp = {
    'experimentID': experimentID,
    'cycle_number' : cycle_number_tmp,
    'search_space_dataset': 'DOE_robot001_3Dim.csv',
    'validated_dataset' : f'/{experimentID}_validated_points.csv', # or None
    'new_points_batch' : new_points_batch_tmp,
    'classifier_model' : 'GaussianProcessClassifier',
    'classifier_dict': classifier_dict_tmp,
    'acquisition_mode': acquisition_mode_tmp,
    'entropy_accuracy' : 1,
    'sampling_mode': 'FPS',
}
```

The code can easily extendable to a loop over multiple cycles, batch of points, acquisition functions or other variables.

### 4. Outputs

Once the cycle is over a bunch of outputs will be generated:
-   csv containig the new batch of points to screen
-   barcode identifiers of the new batch of points
-   original indeces of the points
-   classifier model pkl
-   probability distribution function evaluated over the entire search space
-   json file containing the input configuration

### 5. Additional steps

Additionally, at the end of each cycle a few actions are run:
1.  the new points (not validated) are appended to the master file
2.  the points are validated (robot experiment)
3.  the master file is updated with the validated points

Point 1. is taken care automatically from the `active_learning_cycle.py` script
```python
from robotexperiments.cycle import append_to_masterfile

append_to_masterfile(experimentID=experimentID,
                     cycle_number=cycle_number_tmp,
                     fill_value=0)
```

Point 2. is carried out with the robot.

Point 3. assumes that a file `experimentID_validated_points.csv` is created in the cycle folder containig all the information that the `experimentID_output_points.csv` contains but with the validated value of the target variable.
The master file can be upgraded in a similar way:
```python
from robotexperiments.cycle import update_masterfile

update_masterfile(experimentID=experimentID,
                  cycle_number=cycle_number_tmp,
                  fill_value=0)
```
_Disclaimer_ : _this part needs to be adapted following the specific local implementation!_